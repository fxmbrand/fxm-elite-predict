name: Hourly Prediction Scraper

on:
  schedule:
    # Run every hour at minute 0
    - cron: '0 * * * *'
  
  # Allow manual trigger
  workflow_dispatch:

jobs:
  scrape-and-update:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install aiohttp requests beautifulsoup4
      
      - name: Run SofaScore scraper
        run: |
          python sofascore_scraper.py
      
      - name: Generate HTML data
        run: |
          python generate_html_data.py
      
      - name: Update website
        run: |
          # Copy generated data to website files
          if [ -f "data/predictions.json" ]; then
            echo "âœ“ Predictions data ready"
          fi
      
      - name: Commit and push changes
        run: |
          git config user.name "FXM Bot"
          git config user.email "bot@fxmelitepredict.com"
          
          # Check if there are changes
          if [ -n "$(git status --porcelain)" ]; then
            git add data/predictions.json
            git add index.html predictions.html results.html
            git commit -m "ðŸ¤– Auto-update: Hourly prediction scrape at $(date -u +'%Y-%m-%d %H:%M UTC')"
            git push
            echo "âœ“ Changes pushed successfully"
          else
            echo "â„¹ No changes to commit"
          fi
      
      - name: Update GitHub Pages
        run: |
          echo "âœ“ Website updated at $(date -u +'%Y-%m-%d %H:%M UTC')"
      
      - name: Log execution
        run: |
          echo "Scraper execution completed successfully"
          echo "Next run: $(date -u -d '+1 hour' +'%Y-%m-%d %H:%M UTC')"

  # Notification job (optional)
  notify:
    runs-on: ubuntu-latest
    needs: scrape-and-update
    if: always()
    
    steps:
      - name: Log completion
        run: |
          echo "âœ“ Hourly scraper job completed"
          echo "Status: ${{ needs.scrape-and-update.result }}"
